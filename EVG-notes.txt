
struct SSeq;
struct EVG;

enum ERamNextAction {ERamNextStop, ERamNextSync, ERamNextStart};

struct ERam
{
  EVG *evg;

  uint32_t id; // 0 or 1

  uint32_t ramoffset;

  CALLBACK afterstop;
  CALLBACK sync;

  ERamNextAction next;

  SSeq *owner;
};

// Order of locking is SSeq first, then EVG
// Before modifying allocations take both
// Other operations on an allocated sequence
// take only the SSeq lock

struct EVG {
  ERam rams[2];

  enum {EVGModeSingle, EVGModeDouble} mode;

  volatile const void* base;

  epicsMutex guard;
};

struct SSeq {
  EVG *evg; // SSeq must always have an owner

  epicsUInt8  codes[2047];
  epicsUInt32 times[2047];

  ERam *rams[2];

  epicsMutex guard;
};

class ScopedLock;


void allocate(SSeq *seq)
{
    ScopedLock lock(seq->guard);

    assert(seq->primary==NULL);

    EVG *evg=seq->evg;
    ScopedLock lock(seq->guard);

    if (evg->mode==EVGModeSingle) {
        for(size_t i=0; i<NELEMENTS(EVG::rams); i++) {
            if (!evg->rams[i].owner) {
                evg->rams[i].owner=seq;
                seq->rams[0]=&evg->rams[i];
                break;
            }
        }

    } else if(evg->mode==EVGModeDouble) {
        if (!evg->rams[0] && !evg->rams[1]) {
            seq->rams[0]=&evg->rams[0];
            seq->rams[1]=&evg->rams[1];
        }
    }

    bool fail=!seq->rams[0]

    if (fail)
        throw runtime_error("Allocation could not be satisfied");
}

void deallocate(SSeq *seq)
{
    ScopedLock lock(seq->guard);

    assert(seq->primary!=NULL);

    EVG *evg=seq->evg;
    ScopedLock lock(seq->guard);

    for(size_t i=0; i<NELEMENTS(EVG::rams); i++) {
        if (seq->rams[i]->owner) {
            assert (seq->rams[i]->owner==seq);

            seq->rams[i]->owner=NULL;
            seq->rams[i]=NULL;
            break;
        }
    }

}

void start(SSeq *seq)
{
    ScopedLock lock(seq->guard);

    if (!seq->rams[0])
        return; // unallocated

    // Also set correct mode
    BITSET(seq->owner->base, RAM_CTRL, CTRL_START(seq->rams[0]->id))
}

void stop_now(SSeq *seq)
{
    ScopedLock lock(seq->guard);

    if (!seq->rams[0])
        return; // unallocated

    BITCLR(seq->owner->base, RAM_CTRL, CTRL_STOP(seq->rams[0]->id))

    seq->rams[0]->next=ERamNextStop;

    callbackRequest(seq->rams[0]->afterstop)
    // Will invoke stop_irq_soft
}

void stop_irq_soft(CALLBACK* cb)
{
    ScopedLock lock(seq->guard);
    int flags=epicsInteruptLock();
    stop_irq(seq->evg, seq->rams[0]->id);
    epicsInterruptUnlock(flags);
}

void stop_and(SSeq *seq, ERamNextAction act)
{
    ScopedLock lock(seq->guard);

    if (!seq->rams[0])
        return; // unallocated

    epicsUInt32 ctrl=READ(seq->owner->base, RAM_CTRL) & ~CTRL_MODE_MASK;
    WRITE(seq->owner->base, RAM_CTRL, ctrl&MODE_SINGLE);

    int flags=epicsInteruptLock();
    seq->rams[0]->next=act;
    epicsInterruptUnlock(flags);
    // completes in stop_irq
}

void stop_later(SSeq *seq)
{
    stop_and(seq,ERamNextStop);
}

void stop_irq(EVG *evg, uint32_t ramid)
{
    ERam *ram=&evg->rams[ramid];

    // Ack and disable stop irq

    switch(ram->next) {
    case ERamNextStop:
        break;
    case ERamNextSync:
        callbackRequest(ram->sync);
        break;
    case ERamNextStart:
        start(ram->owner); // Note: can't take mutex
        break;
    }

    // Wake up waiting records
}

void sync(CALLBACK*)
{
    SSeq *seq
    ScopedLock lock(seq->guard);

    ERam *sync;
    if (seq->owner->mode==EVGModeSingle)
        sync=seq->rams[0];
    else
        sync=seq->rams[1];

    // copy to ram

    if (seq->owner->mode==EVGModeSingle){
        start(ram->owner);
    } else if (seq->owner->mode==EVGModeDouble){
        // Swap
        stop_with(seq, ERamNextStart); // stops rams[0]

        ERam *t=seq->rams[0];
        seq->rams[0]=seq->rams[1];
        seq->rams[1]=t;
    }
}

